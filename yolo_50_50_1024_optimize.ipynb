{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a8fdf5-f20d-4918-807d-08b31d5e21ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a54bd76-165e-40ee-b2ae-b772fb442d21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 작업 디렉토리: /home/jovyan/yolov5_quant_sample/npu_optimizer\n",
      "입력 파일 전체 경로: /home/jovyan/yolov5_quant_sample/npu_optimizer/yolo_50_50.pt\n",
      "현재 작업 디렉토리: /home/jovyan/yolov5_quant_sample/npu_optimizer\n",
      "입력 파일 찾음: yolo_50_50.pt\n",
      "1단계: 가중치 최적화 시작...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_360424/3510814355.py:280: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(input_pt_path, map_location='cpu')['model'].float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing conv weights: model.0.conv.weight\n",
      "Optimizing conv weights: model.1.conv.weight\n",
      "Optimizing conv weights: model.2.cv1.conv.weight\n",
      "Optimizing conv weights: model.2.cv2.conv.weight\n",
      "Optimizing conv weights: model.2.cv3.conv.weight\n",
      "Optimizing conv weights: model.2.m.0.cv1.conv.weight\n",
      "Optimizing conv weights: model.2.m.0.cv2.conv.weight\n",
      "Optimizing conv weights: model.2.m.1.cv1.conv.weight\n",
      "Optimizing conv weights: model.2.m.1.cv2.conv.weight\n",
      "Optimizing conv weights: model.3.conv.weight\n",
      "Optimizing conv weights: model.4.cv1.conv.weight\n",
      "Optimizing conv weights: model.4.cv2.conv.weight\n",
      "Optimizing conv weights: model.4.cv3.conv.weight\n",
      "Optimizing conv weights: model.4.m.0.cv1.conv.weight\n",
      "Optimizing conv weights: model.4.m.0.cv2.conv.weight\n",
      "Optimizing conv weights: model.4.m.1.cv1.conv.weight\n",
      "Optimizing conv weights: model.4.m.1.cv2.conv.weight\n",
      "Optimizing conv weights: model.4.m.2.cv1.conv.weight\n",
      "Optimizing conv weights: model.4.m.2.cv2.conv.weight\n",
      "Optimizing conv weights: model.5.conv.weight\n",
      "Optimizing conv weights: model.6.cv1.conv.weight\n",
      "Optimizing conv weights: model.6.cv2.conv.weight\n",
      "Optimizing conv weights: model.6.cv3.conv.weight\n",
      "Optimizing conv weights: model.6.m.0.cv1.conv.weight\n",
      "Optimizing conv weights: model.6.m.0.cv2.conv.weight\n",
      "Optimizing conv weights: model.6.m.1.cv1.conv.weight\n",
      "Optimizing conv weights: model.6.m.1.cv2.conv.weight\n",
      "Optimizing conv weights: model.6.m.2.cv1.conv.weight\n",
      "Optimizing conv weights: model.6.m.2.cv2.conv.weight\n",
      "Optimizing conv weights: model.6.m.3.cv1.conv.weight\n",
      "Optimizing conv weights: model.6.m.3.cv2.conv.weight\n",
      "Optimizing conv weights: model.7.conv.weight\n",
      "Optimizing conv weights: model.8.cv1.conv.weight\n",
      "Optimizing conv weights: model.8.cv2.conv.weight\n",
      "Optimizing conv weights: model.8.cv3.conv.weight\n",
      "Optimizing conv weights: model.8.m.0.cv1.conv.weight\n",
      "Optimizing conv weights: model.8.m.0.cv2.conv.weight\n",
      "Optimizing conv weights: model.8.m.1.cv1.conv.weight\n",
      "Optimizing conv weights: model.8.m.1.cv2.conv.weight\n",
      "Optimizing conv weights: model.9.cv1.conv.weight\n",
      "Optimizing conv weights: model.9.cv2.conv.weight\n",
      "Optimizing conv weights: model.10.conv.weight\n",
      "Optimizing conv weights: model.13.cv1.conv.weight\n",
      "Optimizing conv weights: model.13.cv2.conv.weight\n",
      "Optimizing conv weights: model.13.cv3.conv.weight\n",
      "Optimizing conv weights: model.13.m.0.cv1.conv.weight\n",
      "Optimizing conv weights: model.13.m.0.cv2.conv.weight\n",
      "Optimizing conv weights: model.13.m.1.cv1.conv.weight\n",
      "Optimizing conv weights: model.13.m.1.cv2.conv.weight\n",
      "Optimizing conv weights: model.14.conv.weight\n",
      "Optimizing conv weights: model.17.cv1.conv.weight\n",
      "Optimizing conv weights: model.17.cv2.conv.weight\n",
      "Optimizing conv weights: model.17.cv3.conv.weight\n",
      "Optimizing conv weights: model.17.m.0.cv1.conv.weight\n",
      "Optimizing conv weights: model.17.m.0.cv2.conv.weight\n",
      "Optimizing conv weights: model.17.m.1.cv1.conv.weight\n",
      "Optimizing conv weights: model.17.m.1.cv2.conv.weight\n",
      "Optimizing conv weights: model.18.conv.weight\n",
      "Optimizing conv weights: model.20.cv1.conv.weight\n",
      "Optimizing conv weights: model.20.cv2.conv.weight\n",
      "Optimizing conv weights: model.20.cv3.conv.weight\n",
      "Optimizing conv weights: model.20.m.0.cv1.conv.weight\n",
      "Optimizing conv weights: model.20.m.0.cv2.conv.weight\n",
      "Optimizing conv weights: model.20.m.1.cv1.conv.weight\n",
      "Optimizing conv weights: model.20.m.1.cv2.conv.weight\n",
      "Optimizing conv weights: model.21.conv.weight\n",
      "Optimizing conv weights: model.23.cv1.conv.weight\n",
      "Optimizing conv weights: model.23.cv2.conv.weight\n",
      "Optimizing conv weights: model.23.cv3.conv.weight\n",
      "Optimizing conv weights: model.23.m.0.cv1.conv.weight\n",
      "Optimizing conv weights: model.23.m.0.cv2.conv.weight\n",
      "Optimizing conv weights: model.23.m.1.cv1.conv.weight\n",
      "Optimizing conv weights: model.23.m.1.cv2.conv.weight\n",
      "Optimizing conv weights: model.24.cv2.0.0.conv.weight\n",
      "Optimizing conv weights: model.24.cv2.0.1.conv.weight\n",
      "Optimizing conv weights: model.24.cv2.1.0.conv.weight\n",
      "Optimizing conv weights: model.24.cv2.1.1.conv.weight\n",
      "Optimizing conv weights: model.24.cv2.2.0.conv.weight\n",
      "Optimizing conv weights: model.24.cv2.2.1.conv.weight\n",
      "Optimizing conv weights: model.24.cv3.0.0.conv.weight\n",
      "Optimizing conv weights: model.24.cv3.0.1.conv.weight\n",
      "Optimizing conv weights: model.24.cv3.1.0.conv.weight\n",
      "Optimizing conv weights: model.24.cv3.1.1.conv.weight\n",
      "Optimizing conv weights: model.24.cv3.2.0.conv.weight\n",
      "Optimizing conv weights: model.24.cv3.2.1.conv.weight\n",
      "Optimizing conv weights: model.24.dfl.conv.weight\n",
      "중간 ONNX 저장 중: yolo_50_50_weight_optimized_test.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.10/site-packages/ultralytics/nn/modules/head.py:99: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "/home/jovyan/.local/lib/python3.10/site-packages/ultralytics/utils/tal.py:308: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
      "  for i, stride in enumerate(strides):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2단계: F-LAM 레이어 구조 최적화 시작...\n",
      "Optimizing Concat layer: model\n",
      "Optimizing Concat layer: model\n",
      "Optimizing Concat layer: model\n",
      "Optimizing Concat layer: model\n",
      "Optimizing Concat layer: model\n",
      "Optimizing Concat layer: model\n",
      "Optimizing Concat layer: model\n",
      "Optimizing Concat layer: model\n",
      "Optimizing Concat layer: model\n",
      "Optimizing Concat layer: model\n",
      "Optimizing Concat layer: model\n",
      "Optimizing Concat layer: model\n",
      "Optimizing Concat layer: model\n",
      "Optimizing Concat layer: model\n",
      "Optimizing Concat layer: model\n",
      "Optimizing Concat layer: model\n",
      "Optimizing Concat layer: model\n",
      "Optimizing Concat layer: model\n",
      "Optimizing Concat layer: model\n",
      "Optimizing Concat layer: model\n",
      "Optimizing Concat layer: model\n",
      "Optimizing Concat layer: model\n",
      "Optimizing Concat layer: model\n",
      "Optimizing Concat layer: model\n",
      "Optimizing Concat layer: model\n",
      "Optimizing Add operation: model.2.m.0\n",
      "Optimizing Add operation: model.2.m.1\n",
      "Optimizing Add operation: model.4.m.0\n",
      "Optimizing Add operation: model.4.m.1\n",
      "Optimizing Add operation: model.4.m.2\n",
      "Optimizing Add operation: model.6.m.0\n",
      "Optimizing Add operation: model.6.m.1\n",
      "Optimizing Add operation: model.6.m.2\n",
      "Optimizing Add operation: model.6.m.3\n",
      "Optimizing Add operation: model.8.m.0\n",
      "Optimizing Add operation: model.8.m.1\n",
      "Optimizing MaxPool2d layer: model.9.m\n",
      "Optimizing Upsample layer: model.11\n",
      "Optimizing Add operation: model.13.m.0\n",
      "Optimizing Add operation: model.13.m.1\n",
      "Optimizing Upsample layer: model.15\n",
      "Optimizing Add operation: model.17.m.0\n",
      "Optimizing Add operation: model.17.m.1\n",
      "Optimizing Add operation: model.20.m.0\n",
      "Optimizing Add operation: model.20.m.1\n",
      "Optimizing Add operation: model.23.m.0\n",
      "Optimizing Add operation: model.23.m.1\n",
      "최종 ONNX 저장 중: yolo_50_50_optimized_model_test.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:86: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적화가 성공적으로 완료되었습니다!\n",
      "모든 최적화 단계가 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import onnx\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "from copy import deepcopy\n",
    "\n",
    "class YOLOWeightOptimizer:\n",
    "    \"\"\"가중치 최적화\"\"\"\n",
    "    def __init__(self):\n",
    "        # APACHE5 NPU 파라미터\n",
    "        self.TILE_SIZE = 64\n",
    "        self.CELL_SIZE = 8\n",
    "        self.WFRAM_SIZE = 64 * 1024  # 64KB\n",
    "        self.MAX_BANDWIDTH = 64 * (1024**3) / 8  # 64Gbit/s to Byte/s\n",
    "        self.INT8_MACS = 1024\n",
    "        self.GMAC_CAPACITY = 819.2\n",
    "\n",
    "        # 타일링 관련 상수\n",
    "        self.TILE_SQR = self.TILE_SIZE * self.TILE_SIZE\n",
    "        self.CELL_SQR = self.CELL_SIZE * self.CELL_SIZE\n",
    "        self.CELL_TWI = 2 * self.CELL_SIZE\n",
    "        self.CELL_QUA = 4 * self.CELL_SIZE\n",
    "\n",
    "        # DFL 및 특수 레이어 이름\n",
    "        self.DFL_LAYERS = ['model.24.dfl.conv']\n",
    "        self.CV3_LAYERS = ['model.24.cv3.0.2', 'model.24.cv3.1.2', 'model.24.cv3.2.2']\n",
    "\n",
    "    def _align_channels(self, channels):\n",
    "        \"\"\"채널 수를 CELL_SIZE(8)의 배수로 조정\"\"\"\n",
    "        return ((channels + self.CELL_SIZE - 1) // self.CELL_SIZE) * self.CELL_SIZE\n",
    "\n",
    "    def _scale_for_bandwidth(self, weight):\n",
    "        \"\"\"메모리 대역폭 제약 고려한 스케일링\"\"\"\n",
    "        memory_access = np.prod(weight.shape) * 4  # float32 기준\n",
    "        \n",
    "        if memory_access * self.GMAC_CAPACITY > self.MAX_BANDWIDTH:\n",
    "            scale_factor = self.MAX_BANDWIDTH / (memory_access * self.GMAC_CAPACITY)\n",
    "            weight = weight * scale_factor\n",
    "        \n",
    "        return weight\n",
    "\n",
    "    def optimize_weights(self, model):\n",
    "        \"\"\"가중치 최적화\"\"\"\n",
    "        optimized_state_dict = OrderedDict()\n",
    "        \n",
    "        for name, param in model.state_dict().items():\n",
    "            if 'conv' in name and 'weight' in name:\n",
    "                print(f\"Optimizing conv weights: {name}\")\n",
    "                try:\n",
    "                    optimized_weight = self._optimize_conv_weight(param, name)\n",
    "                    optimized_state_dict[name] = optimized_weight\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: {name} 레이어 최적화 중 오류 발생: {str(e)}\")\n",
    "                    optimized_state_dict[name] = param\n",
    "            else:\n",
    "                optimized_state_dict[name] = param\n",
    "\n",
    "        return optimized_state_dict\n",
    "\n",
    "    def _optimize_conv_weight(self, weight, name):\n",
    "        \"\"\"Convolution 레이어 가중치 최적화\"\"\"\n",
    "        # DFL 레이어는 건너뛰기\n",
    "        if any(dfl_name in name for dfl_name in self.DFL_LAYERS):\n",
    "            return weight\n",
    "            \n",
    "        out_channels, in_channels, kernel_h, kernel_w = weight.shape\n",
    "        \n",
    "        # 첫 번째 레이어 또는 cv3 레이어 특별 처리\n",
    "        if in_channels == 3 or any(cv3_name in name for cv3_name in self.CV3_LAYERS):\n",
    "            return self._optimize_special_layers(weight, name)\n",
    "            \n",
    "        # 기본 채널 정렬\n",
    "        aligned_out = self._align_channels(out_channels)\n",
    "        aligned_in = self._align_channels(in_channels)\n",
    "        \n",
    "        # 가중치 재구성\n",
    "        new_weight = torch.zeros(aligned_out, aligned_in, kernel_h, kernel_w)\n",
    "        \n",
    "        # 실제 복사할 크기 계산\n",
    "        copy_out = min(out_channels, aligned_out)\n",
    "        copy_in = min(in_channels, aligned_in)\n",
    "        \n",
    "        # 안전하게 가중치 복사\n",
    "        new_weight[:copy_out, :copy_in, :, :] = weight[:copy_out, :copy_in, :, :]\n",
    "        \n",
    "        # 새로운 영역 초기화\n",
    "        if aligned_out > copy_out or aligned_in > copy_in:\n",
    "            scaling = np.sqrt(2.0 / (aligned_in * kernel_h * kernel_w))\n",
    "            mask = torch.zeros_like(new_weight)\n",
    "            mask[copy_out:, :, :, :] = 1\n",
    "            mask[:, copy_in:, :, :] = 1\n",
    "            \n",
    "            # Xavier/Glorot 초기화 사용\n",
    "            limit = np.sqrt(6 / ((copy_out + aligned_out) * kernel_h * kernel_w))\n",
    "            rand_weight = torch.empty_like(new_weight).uniform_(-limit, limit)\n",
    "            new_weight = new_weight * (1 - mask) + rand_weight * mask\n",
    "        \n",
    "        return self._scale_for_bandwidth(new_weight)\n",
    "\n",
    "    def _optimize_special_layers(self, weight, name):\n",
    "        \"\"\"특수 레이어 (첫 번째 레이어, cv3 레이어) 최적화\"\"\"\n",
    "        if any(cv3_name in name for cv3_name in self.CV3_LAYERS):\n",
    "            return self._optimize_cv3_layer(weight)\n",
    "        elif weight.shape[1] == 3:  # 첫 번째 레이어\n",
    "            return self._optimize_first_layer(weight)\n",
    "        return weight\n",
    "\n",
    "    def _optimize_first_layer(self, weight):\n",
    "        \"\"\"첫 번째 레이어 최적화\"\"\"\n",
    "        out_channels, in_channels, kernel_h, kernel_w = weight.shape\n",
    "        \n",
    "        # 출력 채널만 8의 배수로 조정\n",
    "        aligned_out = self._align_channels(out_channels)\n",
    "        new_weight = torch.zeros(aligned_out, in_channels, kernel_h, kernel_w)\n",
    "        \n",
    "        # 가중치 복사\n",
    "        copy_out = min(out_channels, aligned_out)\n",
    "        new_weight[:copy_out, :, :, :] = weight[:copy_out, :, :, :]\n",
    "        \n",
    "        # 새로운 채널 초기화\n",
    "        if aligned_out > copy_out:\n",
    "            scaling = np.sqrt(2.0 / (in_channels * kernel_h * kernel_w))\n",
    "            new_weight[copy_out:, :, :, :] = torch.randn_like(new_weight[copy_out:, :, :, :]) * scaling\n",
    "            \n",
    "        return new_weight\n",
    "\n",
    "    def _optimize_cv3_layer(self, weight):\n",
    "        \"\"\"cv3 레이어 최적화\"\"\"\n",
    "        out_channels, in_channels, kernel_h, kernel_w = weight.shape\n",
    "        \n",
    "        # 입력 채널만 8의 배수로 조정 (출력은 원래 크기 유지)\n",
    "        aligned_in = self._align_channels(in_channels)\n",
    "        new_weight = torch.zeros(out_channels, aligned_in, kernel_h, kernel_w)\n",
    "        \n",
    "        # 실제 복사할 크기 계산\n",
    "        copy_in = min(in_channels, aligned_in)\n",
    "        \n",
    "        # 안전하게 가중치 복사\n",
    "        new_weight[:, :copy_in, :, :] = weight[:, :copy_in, :, :]\n",
    "        \n",
    "        # 새로운 채널 초기화\n",
    "        if aligned_in > copy_in:\n",
    "            scaling = np.sqrt(2.0 / (aligned_in * kernel_h * kernel_w))\n",
    "            new_weight[:, copy_in:, :, :] = torch.randn_like(new_weight[:, copy_in:, :, :]) * scaling\n",
    "\n",
    "        return new_weight\n",
    "\n",
    "class YOLOStructureOptimizer:\n",
    "    \"\"\"F-LAM 레이어 구조 최적화\"\"\"\n",
    "    def __init__(self):\n",
    "        self.TILE_SIZE = 64\n",
    "        self.WFRAM_SIZE = 64 * 1024\n",
    "        self.TILE_SQR = self.TILE_SIZE * self.TILE_SIZE\n",
    "\n",
    "    def optimize_structure(self, model):\n",
    "        \"\"\"F-LAM 레이어 구조 최적화\"\"\"\n",
    "        optimized_model = deepcopy(model)\n",
    "        \n",
    "        # 원본 forward 메소드 저장\n",
    "        original_forward = optimized_model.forward\n",
    "        \n",
    "        def unified_forward(self, x):\n",
    "            # 원본 forward 실행\n",
    "            outputs = original_forward(x)\n",
    "            # 단일 출력만 반환\n",
    "            if isinstance(outputs, (list, tuple)):\n",
    "                return outputs[0]  # 첫 번째 출력만 반환\n",
    "            return outputs\n",
    "        \n",
    "        # 새로운 forward 메소드 설정\n",
    "        optimized_model.forward = unified_forward.__get__(optimized_model)\n",
    "        \n",
    "        # F-LAM 레이어 최적화\n",
    "        for name, module in optimized_model.named_modules():\n",
    "            # Concat 최적화\n",
    "            if isinstance(module, torch.nn.modules.container.Sequential):\n",
    "                for layer in module:\n",
    "                    if hasattr(layer, 'f') and isinstance(layer.f, (list, int)):\n",
    "                        print(f\"Optimizing Concat layer: {name}\")\n",
    "                        self._optimize_concat_layer(layer)\n",
    "            \n",
    "            # Add 최적화\n",
    "            if hasattr(module, 'add'):\n",
    "                print(f\"Optimizing Add operation: {name}\")\n",
    "                self._optimize_add_operation(module)\n",
    "            \n",
    "            # Upsample 최적화\n",
    "            if isinstance(module, torch.nn.Upsample):\n",
    "                print(f\"Optimizing Upsample layer: {name}\")\n",
    "                self._optimize_upsample_layer(module)\n",
    "            \n",
    "            # MaxPool2d 최적화\n",
    "            if isinstance(module, torch.nn.MaxPool2d):\n",
    "                print(f\"Optimizing MaxPool2d layer: {name}\")\n",
    "                self._optimize_maxpool_layer(module)\n",
    "\n",
    "        return optimized_model\n",
    "\n",
    "    def _optimize_flam_output(self, x):\n",
    "        \"\"\"F-LAM 출력 크기 최적화\"\"\"\n",
    "        if x is None:\n",
    "            return None\n",
    "            \n",
    "        total_size = np.prod(x.shape[2:])\n",
    "        if total_size > self.TILE_SQR:\n",
    "            scale = np.sqrt(self.TILE_SQR / total_size)\n",
    "            return torch.nn.functional.interpolate(\n",
    "                x,\n",
    "                scale_factor=scale,\n",
    "                mode='bilinear',\n",
    "                align_corners=False\n",
    "            )\n",
    "        return x\n",
    "\n",
    "    def _optimize_concat_layer(self, layer):\n",
    "        original_forward = layer.forward\n",
    "        optimizer = self\n",
    "        \n",
    "        def optimized_forward(self, x):\n",
    "            if isinstance(x, list):\n",
    "                x = [optimizer._optimize_flam_output(f) for f in x]\n",
    "            return original_forward(x)\n",
    "        \n",
    "        layer.forward = optimized_forward.__get__(layer)\n",
    "        \n",
    "    def _optimize_add_operation(self, module):\n",
    "        original_forward = module.forward\n",
    "        optimizer = self\n",
    "        \n",
    "        def optimized_forward(self, x):\n",
    "            if isinstance(x, tuple):\n",
    "                x = tuple(optimizer._optimize_flam_output(t) for t in x)\n",
    "            return original_forward(x)\n",
    "        \n",
    "        module.forward = optimized_forward.__get__(module)\n",
    "\n",
    "    def _optimize_upsample_layer(self, module):\n",
    "        original_forward = module.forward\n",
    "        optimizer = self\n",
    "        \n",
    "        def optimized_forward(self, x):\n",
    "            x = optimizer._optimize_flam_output(x)\n",
    "            result = original_forward(x)\n",
    "            return optimizer._optimize_flam_output(result)\n",
    "        \n",
    "        module.forward = optimized_forward.__get__(module)\n",
    "\n",
    "    def _optimize_maxpool_layer(self, module):\n",
    "        original_forward = module.forward\n",
    "        optimizer = self\n",
    "        \n",
    "        def optimized_forward(self, x):\n",
    "            x = optimizer._optimize_flam_output(x)\n",
    "            result = original_forward(x)\n",
    "            return optimizer._optimize_flam_output(result)\n",
    "        \n",
    "        module.forward = optimized_forward.__get__(module)\n",
    "\n",
    "def optimize_yolo_model(input_pt_path, output_onnx_path, intermediate_onnx_path=None):\n",
    "    \"\"\"YOLO 모델 최적화\"\"\"\n",
    "    try:\n",
    "        # 현재 작업 디렉토리 확인 및 출력\n",
    "        current_dir = os.getcwd()\n",
    "        print(f\"현재 작업 디렉토리: {current_dir}\")\n",
    "        \n",
    "        # 입력 파일 확인\n",
    "        if not os.path.exists(input_pt_path):\n",
    "            print(f\"입력 파일을 찾을 수 없음: {input_pt_path}\")\n",
    "            raise FileNotFoundError(f\"입력 모델을 찾을 수 없습니다: {input_pt_path}\")\n",
    "        else:\n",
    "            print(f\"입력 파일 찾음: {input_pt_path}\")\n",
    "        \n",
    "        # 출력 디렉토리 생성\n",
    "        os.makedirs(os.path.dirname(output_onnx_path) or '.', exist_ok=True)\n",
    "        if intermediate_onnx_path:\n",
    "            os.makedirs(os.path.dirname(intermediate_onnx_path) or '.', exist_ok=True)\n",
    "\n",
    "        print(\"1단계: 가중치 최적화 시작...\")\n",
    "        model = torch.load(input_pt_path, map_location='cpu')['model'].float()\n",
    "        model.eval()\n",
    "        \n",
    "        # 1단계: 가중치 최적화\n",
    "        weight_optimizer = YOLOWeightOptimizer()\n",
    "        optimized_weights = weight_optimizer.optimize_weights(model)\n",
    "        model.load_state_dict(optimized_weights)\n",
    "        \n",
    "        # 중간 ONNX 저장 (가중치만 최적화된 상태)\n",
    "        if intermediate_onnx_path:\n",
    "            print(f\"중간 ONNX 저장 중: {intermediate_onnx_path}\")\n",
    "            dummy_input = torch.randn(1, 3, 384, 640)\n",
    "            torch.onnx.export(\n",
    "                model,\n",
    "                dummy_input,\n",
    "                intermediate_onnx_path,\n",
    "                verbose=False,\n",
    "                opset_version=12,\n",
    "                input_names=['images'],\n",
    "                output_names=['output']\n",
    "            )\n",
    "\n",
    "        print(\"2단계: F-LAM 레이어 구조 최적화 시작...\")\n",
    "        # 2단계: 구조 최적화\n",
    "        structure_optimizer = YOLOStructureOptimizer()\n",
    "        final_model = structure_optimizer.optimize_structure(model)\n",
    "        \n",
    "        # 최종 ONNX 저장\n",
    "        print(f\"최종 ONNX 저장 중: {output_onnx_path}\")\n",
    "        dummy_input = torch.randn(1, 3, 384, 640)\n",
    "        torch.onnx.export(\n",
    "            final_model,\n",
    "            dummy_input,\n",
    "            output_onnx_path,\n",
    "            verbose=False,\n",
    "            opset_version=12,\n",
    "            input_names=['images'],\n",
    "            output_names=['output'],\n",
    "            dynamic_axes=None,  # dynamic axes 비활성화\n",
    "        )\n",
    "        \n",
    "        print(\"최적화가 성공적으로 완료되었습니다!\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"최적화 중 오류 발생: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "# 실행 예시\n",
    "if __name__ == \"__main__\":\n",
    "    # 경로 설정\n",
    "    input_pt_path = \"yolo_50_50.pt\"\n",
    "    output_onnx_path = \"yolo_50_50_optimized_model_test.onnx\"\n",
    "    intermediate_onnx_path = \"yolo_50_50_weight_optimized_test.onnx\"\n",
    "    \n",
    "    # 현재 경로 출력\n",
    "    current_dir = os.getcwd()\n",
    "    print(f\"현재 작업 디렉토리: {current_dir}\")\n",
    "    print(f\"입력 파일 전체 경로: {os.path.abspath(input_pt_path)}\")\n",
    "    \n",
    "    # 최적화 실행\n",
    "    try:\n",
    "        success = optimize_yolo_model(\n",
    "            input_pt_path=input_pt_path,\n",
    "            output_onnx_path=output_onnx_path,\n",
    "            intermediate_onnx_path=intermediate_onnx_path\n",
    "        )\n",
    "        \n",
    "        if success:\n",
    "            print(\"모든 최적화 단계가 완료되었습니다.\")\n",
    "        else:\n",
    "            print(\"최적화 중 오류가 발생했습니다.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"실행 중 오류 발생: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
